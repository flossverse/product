\section{HCI}
\subsection{MoveAI}
\href{https://www.from-the-interface.com/wrist-interfaces/}{Meta's wrist reader}\\
\href{https://scitechdaily.com/groundbreaking-new-technology-allows-people-to-listen-to-music-through-touch/}{Touch music interface}\\
\subsection{Interface and tracking}
\subsubsection{Pose estimations}
\href{https://www.standablevr.com/}{Standable}\\
\href{https://microsoft.github.io/DenseLandmarks/}{Dense face fields from Microsoft}\\
\section{Usability
\href{https://www.businessinsider.com/mcdonalds-metaverse-virtual-online-restaurant-trademark-delivers-fod-web3-nft}{ridging the real and the virtual like mcdonalds home delivery}\\-2022-2}
\section{legal / governance / privacy}
\subsection{legal jeopardy for celebrities}
\href{https://www.smashingmagazine.com/printed-books/understanding-privacy/#bookTOC}{Privacy law book}\\
\href{https://webdevlaw.uk/2022/11/21/a-quick-hypothetical-situation-or-your-crash-introduction-to-the-real-world/}{Online safety bill heather articles}\\
\section{Omniverse}
\href{https://blogs.nvidia.com/blog/2022/01/04/omniverse-available-free-to-creators/}{Free to individuals}\\
\href{https://www.youtube.com/watch?v=Jm155QkRjl0&feature=youtu.be}{Full RTX rendering}\\
\section{Narratives and convergence}
\subsection{With the help of generative AI it may be possible to democratise the externalisation of complex narratives, with these new narratives shaping the outcomes of society} \subsection{Games is the main convergence}
\section{Virtual land}
\subsection{virtual}
\href{https://labusinessjournal.com/featured/metahouse-could-be-first-of-many/}{hybrid land linking real and virtual (including digital twin)}\\
\subsection{Simple geo-referencing of physical place in mixed reality}
\section{Fantastical NeRFs}
\subsection{waiting on capture}
\subsubsection{use polycam}
\subsubsection{try the BTS cam?}
\href{https://www.matthewtancik.com/nerf}{Nerfs}\\
\href{https://github.com/sxyu/volrend}{viewier}\\
\subsection{Windows NeRF environment to WebGL}
\href{https://github.com/bycloudai/instant-ngp-Windows}{install windows NeRF}\\
\subsection{check out mip nerf 360s}
\href{https://github.com/marek-simonik/record3d_unity_streaming}{Record3D}\\
\href{https://github.com/yenchenlin/awesome-NeRF}{github of links}\\
\href{https://www.linkedin.com/posts/robcsloan_nerfstudio-nerfstudio-polycam-activity-6999169160379297792-SN4F?utm_source=share&utm_medium=member_deskto>}{nerfs with polycam}\\
\href{https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#polycam-capture}{Polycam developer mode instructions}\\
\href{https://elicit3d.github.io/}{Nerf to animated people oneshot}\\
\href{https://paperswithcode.com/paper/4k-nerf-high-fidelity-neural-radiance-fields}{4K ultra high res nerfs with code}\\
\href{https://github.com/frozoul/4K-NeRF}{code}\\
\href{https://www.reddit.com/r/deeplearning/comments/zowgqn/neural_rendering_reconstruct_your_city_in_3d/}{city modelling}\\
\href{https://waymo.com/research/block-nerf/}{more city modelling}\\
\href{https://github.com/3a1b2c3/seeingSpace/wiki/Hands-on:-Getting-started-and-Nerf-frameworks}{field guide}\\
\href{https://github.com/ToniRV/NeRF-SLAM}{NeRF SLAM}\\
\href{https://www.xxlong.site/NeuralUDF/}{NeuralUDF surface capture}\\
images
\href{https://github.com/mattdesl/gifenc}{Colour palette extraction}\\
\href{https://arxiv.org/abs/2210.09276}{Text based real time image manipulation}\\
\href{https://www.youtube.com/watch?v=lHcPtbZ0Mnc}{Google prompt to prompt image remodeller}\\
\href{https://github.com/google/prompt-to-prompt}{github}\\
\href{https://replicate.com/methexis-inc#}{Img2Prompt}\\
\href{https://deepimagination.cc/eDiffi/}{eDiffi nvidia text to image}\\
\href{https://laion.ai/blog/laion-coco/}{Image to caption}\\
\href{https://github.com/Sanster/lama-cleaner}{lama image cleanup}\\
\subsection{Stability specific tools}
\subsubsection{Stable diffusion}
\href{https://jalammar.github.io/illustrated-stable-diffusion/}{Illustrated overview}\\
\href{https://www.thosesixfaces.com/post/stable-diffusion-getting-started-windows}{Automatic1111 GUI and user guide}\\
\href{citivia browser}{https://github.com/Vetchems/sd-civitai-browser}{\subsection\\
\textbf{prompt engineering links}
\subsection{Birme image resizer}
\href{https://docs.google.com/document/d/1cbMnxlxngPfqo3i0_miLZiHt-S5mtSNotjdFAEizooA/edit?usp=sharing}{Set matching pipeline for Pathway}\\
\href{https://github.com/AUTOMATIC1111/stable-diffusion-webui}{Automatic WebUI}\\
\href{https://www.reddit.com/r/StableDiffusion/comments/xgurs3/testing_img2img_batch_processing_i_convert_this/}{Img2Img guide from reddit for face mapping}\\
\href{https://github.com/rinongal/textual_inversion}{textual inversion cheaper training}\\
\href{https://danieljeffries.substack.com/p/the-turning-point-for-truly-open?sd=pf}{CIO blog post}\\
\href{https://www.youtube.com/watch?v=lHcPtbZ0Mnc}{google stable diffusion}\\
\href{https://github.com/bloc97/CrossAttentionControl}{Cross attention replace named items}\\
\href{https://the-decoder.com/stable-diffusion-could-soon-generate-images-much-faster/}{256 x faster speedup}\\
\href{https://github.com/VoltaML/voltaML-fast-stable-diffusion}{VoltaML acceleration}\\
\href{https://www.youtube.com/watch?v=AeDngG9kQNI}{Depth map into blender from SD2}\\
\href{https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/}{midjourney tweaks}\\
\href{https://rentry.org/sdupdates3}{Updates Pastebin}\\
\href{https://www.reddit.com/r/StableDiffusion/comments/100tp0v/protogenx34_has_absolutely_amazing_detail/}{Protogen3 model is nice}\\
\subsubsection{librefold}
\href{https://upscale.wiki/wiki/Model_Database}{upscalers}\\
\href{https://github.com/upscayl/upscayl}{upscayl}\\
\section{video}
\href{https://www.youtube.com/c/RunwayML}{Runway AI video editing}\\
\href{https://film-net.github.io/}{Interpolation between two frames}\\
\subsection{Video slowmo and enhance}
\href{https://github.com/HelixNGC7293/DeforumStableDiffusionLocal}{deforum stable diffusion video}\\
\href{https://phenaki.video/}{Phenaki}\\
\href{https://twitter.com/cut_pow/status/1576748659051749377}{Interframe consistency is now here}\\
\subsection{Collaborative video pipeline}
\subsubsection{2nd meeting with electric sheep}
\href{https://magicvideo.github.io/}{Magicvideo (faster)}\\
\href{https://studios.disneyresearch.com/2022/11/30/production-ready-face-re-aging-for-visual-effects/}{Production ready re aging}\\
\href{https://arxiv.org/abs/2202.00512}{distilled models for 25fps}\\
\section{human stuff}
\href{https://dl.acm.org/doi/abs/10.1145/3528233.3530740}{Volumetric primitives (MVP) avatar representation of Lombardi et al. [2021].}\\
\href{https://arxiv.org/abs/2205.06254}{Single shot vertex fitting}\\
\href{https://meshcapade.com/}{Meshcapade virtual humans}\\
\href{https://share.synthesia.io/a5a12c73-09cb-4455-b007-147ae4b1effb}{AI video actor}\\
\href{https://ofa-sys.github.io/MoFusion/}{text to human motion}\\
\href{https://talkshow.is.tue.mpg.de/}{text to speech to simulated speaking movement}\\
\href{https://www.linkedin.com/posts/reneschulte_nerf-deeplearning-metaverse-activity-7010898662465617921-56P_?utm_source=share&utm_medium=member_desktop}{nerf avatars}\\
\href{https://twitter.com/IntuitMachine/status/1608690077139599360}{chatgpt to avatar}\\
\href{https://www.mmlab-ntu.com/project/vtoonify/}{toonify code and model}\\
\href{https://github.com/Meta-Portrait/MetaPortrait}{Talking head modifier}\\
\href{https://www.d-id.com/}{AI face studio}\\
\subsection{MoveAI}
\href{https://3d-avatar-diffusion.microsoft.com/?utm_campaign=AI%20Art%20Weekly&utm_medium=email&utm_source=Revue%20newsletter#/}{Microsoft sculpted avatars}\\
\section{geom}
\href{https://samsunglabs.github.io/rome/}{geom head from single shot}\\
\href{https://www.youtube.com/watch?v=uboj01Gfy1A}{Microsoft AI faces}\\
\href{https://replicate.com/yoyo-nb/thin-plate-spline-motion-model}{Face to face mapping}\\
\href{https://katjaschwarz.github.io/voxgraf/}{Image to voxel faces}\\
\subsection{3D model from text}
\href{https://nv-tlabs.github.io/GET3D/}{GET3D}\\
\href{https://github.com/openai/point-e}{openai point-e}\\
\href{https://ajayj.com/dreamfields}{Dream3D}\\
\href{https://katjaschwarz.github.io/voxgraf/}{Image to voxel faces}\\
\href{https://nv-tlabs.github.io/GET3D/}{GET3D}\\
\href{https://github.com/autodeskailab/clip-forge}{Clipforge}\\
\href{https://paperswithcode.com/paper/text-to-mesh-without-3d-supervision-using}{clip mesh}\\
\href{https://nv-tlabs.github.io/LION/}{LION instant 3D textured geom}\\
\href{https://github.com/carson-katri/dream-textures/pull/409}{Geom texturing from prompts in blender}\\
\href{https://twitter.com/TomLikesRobots/status/1603884188326940674}{blender 3d from 2d twitter thread}\\
\href{https://github.com/zoomin-lee/scene-scale-diffusion}{composite scene generation}\\
\section{AI/ML}
\href{https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/how-should-we-assess-securiy-and{AI security considerations}\\-data-minimisation-in-ai/>}
\href{https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R/view}{Meta research paper}\\
\subsection{implementations}
\subsubsection{pytorch/numpty}
\subsubsection{tensorflow/jax}
\subsection{HCI}
\href{https://www.from-the-interface.com/wrist-interfaces/}{Meta's wrist reader}\\
\href{https://twitter.com/daniel_eckler/status/1564601398284664832?s=20&t=79zgNMrzbD89cQto2u5j-Q}{ML verticals twitter thread}\\
\href{Automatic1111 robot plugin}{https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Developing-extensions}\\
\subsection{2D to blender 3D workflow.}
\section{games dev}
\href{https://www.traffickinggame.com/ai-assisted-graphics}
